---
title: "Omar Rivasplata"
author: ["Omar Rivasplata"]
lastmod: 2023-11-10T21:10:00+00:00
draft: false
weight: 3002
active: true
superuser: false
role: "Senior Lecturer in Machine Learning"
organizations:
  - name: "University of Manchester"
    url: "https://www.manchester.ac.uk/"
  - name: "Personal Webpage"
    url: "https://personalpages.manchester.ac.uk/staff/omar.rivasplata/"

# Interests to show in About widget
interests:
  - Machine Learning
  - Statistical Learning Theory
  - Risk bounds, PAC-Bayes
  - Optimisation & Certification
  - Probabilistic Methods

  
# Highlight the author in author lists? (true/false)
highlight_name: false

# Organizational groups that you belong to (for People widget)
#   Remove this if you are not using the People widget.
user_groups:
- Supervisor
---

I am Associate Professor (Senior Lecturer) in Machine Learning in the Department of Computer Science at the University of Manchester. I am also a member of the [Centre for AI Fundamentals](https://ai-fun.manchester.ac.uk/) and a supervisor in the [UKRI AI CDT in Decision Making for Complex Systems](https://www.ai-decisions-cdt.ac.uk/). 

My research is on machine learning, theory and practice. That said, I tend to have a broad interest in various aspects of the mathematical and statistical foundations of machine learning and AI in general. In the limit of tending to praxis, I work on designing strategies to train and certify machine learning models. Previously, I have led or been a contributor to projects on offline reinforcement learning, generative models, PAC-Bayes bounds for deep learning and kernel classifiers, among other.

The field of machine learning research is fascinating! One of the things I enjoy most about my work being the confluence of maths and stats, and computer experiments with collaborators, to answer questions about the optimisation and certification of machine learning models. Besides statistical learning I am interested also in online learning and reinforcement learning. Of course I am interested in deep learning, which is quite popular these days. Optimisation is a pervasive theme across machine learning theory and practice, though it comes up in such a variety of flavours and colours that it isn't boring. It reminds of the [least action principle](https://en.wikipedia.org/wiki/Stationary-action_principle) of [Maupertuis](https://en.wikipedia.org/wiki/Pierre_Louis_Maupertuis), saying that "everything happens as if some quantity was to be made as small as possible." (This principle has lead the optimists to believe that we live in [the best possible world](https://www.google.co.uk/books/edition/_/WGOmFLikLrkC?hl=en).) But just optimisation doesn't quite do it for machine learning... to really be talking about learning one has to pay attention to learner's performance beyond the data used for training; so certification is very important!

